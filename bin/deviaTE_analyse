#!/usr/bin/env python3

import argparse
import pysam
import deviaTE.deviaTE_pileup as pileup
from deviaTE.deviaTE_IO import get_data, get_ref, get_anno, get_norm_fac


# set up parser and arguments
parser = argparse.ArgumentParser()
parser.add_argument('--input', required=True, help='alignment file to be analysed')
parser.add_argument('--family', required=True, help='TE family to analyse')
parser.add_argument('--library', help='path to alternative reference sequence library')
parser.add_argument('--output', help='name of output table')
parser.add_argument('--sample_id', help='sample identifier')
parser.add_argument('--annotation', help='alternative annotation in gff-format')
parser.add_argument('--log', help='logfile from preparation script')
args = parser.parse_args()

if args.sample_id is None:
    args.sample_id = args.input

if args.output is None:
    args.output = args.sample_id + '.' + args.family

if args.library is None:
    args.library = get_data('lib/te_library')

if args.annotation is None:
    args.annotation = get_data('lib/te_features.gff')


# look for the refseq of chosen family
refseq = get_ref(lib=args.library, fam=args.family)

if refseq is None:
    raise ValueError('Selected family is not in references. Typo? ' + args.family)
else:
    pileup.Site.name = args.family # fam as class variable


# get annotation for the selected family
fam_anno = get_anno(annotations=args.annotation, fam=args.family)

if len(fam_anno) is 0:
    print('no annotaions found for: ' + args.family)

    
# search the logfile, if provided, for normalization factor
norm_fac = get_norm_fac(log=args.log)


# create a list of Site instances
sites = []
c = 0
for base in refseq:
    sites.append(pileup.Site(pos=c, refbase=base, sid=args.sample_id, fam=args.family))
    c += 1


# open the alignment file for data extraction
bamfile_op = pysam.AlignmentFile(args.input, 'rb')

pileup.perform_pileup(sitelist=sites, bam=bamfile_op, min_int_del_len=20,
                      min_trunc_len=10, min_indel_len=2)

bamfile_op.close()

# process the extracted data
for site in sites:
    site.sum_coverage()
    site.is_snp(min_count=5, min_freq=0.05, A=site.A, C=site.C, G=site.G, T=site.T, cov=site.cov)
    site.filter_IND(att='int_del', min_count=3, norm_fac=norm_fac)
    site.filter_IND(att='ins', min_count=5, norm_fac=norm_fac)
    site.filter_IND(att='delet', min_count=5, norm_fac=norm_fac)
    site.filter_trunc(min_trunc_count=3)
    site.check_annotation(anno=fam_anno)
    if norm_fac is not 1:
        site.normalize(norm_factor=norm_fac)

# write the results
pileup.Site.write_frame(sites=sites, out=args.output)
print('analysis completed; table written to: ' + args.output)
